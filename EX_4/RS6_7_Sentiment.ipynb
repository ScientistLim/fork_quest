{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4db0cbef",
   "metadata": {},
   "source": [
    "# 7.4: 텍스트 데이터의 특징 \n",
    "## (1) 텍스트를 숫자로 표현하는 방법\n",
    "### Author: Jiwon Kim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f1dea64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'feel', 'hungry']\n"
     ]
    }
   ],
   "source": [
    "# 처리해야 할 문장을 파이썬 리스트에 옮겨 담았습니다.\n",
    "sentences=['i feel hungry', 'i eat lunch', 'now i feel happy']\n",
    "\n",
    "# 파이썬 split() 메소드를 이용해 단어 단위로 문장을 쪼개 봅니다.\n",
    "word_list = 'i feel hungry'.split()\n",
    "print(word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c573d83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: '<PAD>', 1: '<BOS>', 2: '<UNK>', 3: 'i', 4: 'feel', 5: 'hungry', 6: 'eat', 7: 'lunch', 8: 'now', 9: 'happy'}\n"
     ]
    }
   ],
   "source": [
    "index_to_word={}  # 빈 딕셔너리를 만들어서\n",
    "\n",
    "# 단어들을 하나씩 채워 봅니다. 채우는 순서는 일단 임의로 하였습니다. 그러나 사실 순서는 중요하지 않습니다. \n",
    "# <BOS>, <PAD>, <UNK>는 관례적으로 딕셔너리 맨 앞에 넣어줍니다. \n",
    "index_to_word[0]='<PAD>'  # 패딩용 단어\n",
    "index_to_word[1]='<BOS>'  # 문장의 시작지점\n",
    "index_to_word[2]='<UNK>'  # 사전에 없는(Unknown) 단어\n",
    "index_to_word[3]='i'\n",
    "index_to_word[4]='feel'\n",
    "index_to_word[5]='hungry'\n",
    "index_to_word[6]='eat'\n",
    "index_to_word[7]='lunch'\n",
    "index_to_word[8]='now'\n",
    "index_to_word[9]='happy'\n",
    "\n",
    "print(index_to_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e82d4c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<PAD>': 0, '<BOS>': 1, '<UNK>': 2, 'i': 3, 'feel': 4, 'hungry': 5, 'eat': 6, 'lunch': 7, 'now': 8, 'happy': 9}\n"
     ]
    }
   ],
   "source": [
    "word_to_index={word:index for index, word in index_to_word.items()}\n",
    "print(word_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1c8a438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(word_to_index['feel'])  # 단어 'feel'은 숫자 인덱스 4로 바뀝니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df6a6c25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 6, 7]\n"
     ]
    }
   ],
   "source": [
    "# 문장 1개를 활용할 딕셔너리와 함께 주면, 단어 인덱스 리스트로 변환해 주는 함수를 만들어 봅시다.\n",
    "# 단, 모든 문장은 <BOS>로 시작하는 것으로 합니다. \n",
    "def get_encoded_sentence(sentence, word_to_index):\n",
    "    return [word_to_index['<BOS>']]+[word_to_index[word] if word in word_to_index else word_to_index['<UNK>'] for word in sentence.split()]\n",
    "\n",
    "print(get_encoded_sentence('i eat lunch', word_to_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8a7d5ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]]\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 문장 리스트를 한꺼번에 숫자 텐서로 encode해 주는 함수입니다. \n",
    "def get_encoded_sentences(sentences, word_to_index):\n",
    "    return [get_encoded_sentence(sentence, word_to_index) for sentence in sentences]\n",
    "\n",
    "# sentences=['i feel hungry', 'i eat lunch', 'now i feel happy'] 가 아래와 같이 변환됩니다. \n",
    "encoded_sentences = get_encoded_sentences(sentences, word_to_index)\n",
    "print(encoded_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa94cc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i feel hungry\n"
     ]
    }
   ],
   "source": [
    "# 숫자 벡터로 encode된 문장을 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentence(encoded_sentence, index_to_word):\n",
    "    return ' '.join(index_to_word[index] if index in index_to_word else '<UNK>' for index in encoded_sentence[1:])  #[1:]를 통해 <BOS>를 제외\n",
    "\n",
    "print(get_decoded_sentence([1, 3, 4, 5], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7fae222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i feel hungry', 'i eat lunch', 'now i feel happy']\n"
     ]
    }
   ],
   "source": [
    "# 여러 개의 숫자 벡터로 encode된 문장을 한꺼번에 원래대로 decode하는 함수입니다. \n",
    "def get_decoded_sentences(encoded_sentences, index_to_word):\n",
    "    return [get_decoded_sentence(encoded_sentence, index_to_word) for encoded_sentence in encoded_sentences]\n",
    "\n",
    "# encoded_sentences=[[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 가 아래와 같이 변환됩니다.\n",
    "print(get_decoded_sentences(encoded_sentences, index_to_word))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8abbf452",
   "metadata": {},
   "source": [
    "- 임의로 부여된 단어 순서임 \n",
    "- 실제 필요한 프로세스: 단어와 그 단어의 의미를 나타내는 벡터를 짝짓는 것이었습니다. 그래서 단어의 의미를 나타내는 벡터를 훈련 가능한 파라미터로 놓고 이를 딥러닝을 통해 학습해서 최적화하게 됩니다. Tensorflow, Pytorch 등의 딥러닝 프레임워크들은 이러한 의미 벡터 파라미터를 구현한 Embedding 레이어를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7dceb1df",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to convert a NumPy array to a Tensor (Unsupported object type list).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_113/2733197300.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mraw_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_encoded_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword_to_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'object'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    983\u001b[0m     if any(isinstance(x, (\n\u001b[1;32m    984\u001b[0m         tf.Tensor, np.ndarray, float, int)) for x in input_list):\n\u001b[0;32m--> 985\u001b[0;31m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    986\u001b[0m       \u001b[0minput_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 869\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_convert_numpy_or_python_types\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m   3297\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_convert_numpy_or_python_types\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3298\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3299\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3300\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2_with_dispatch\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1428\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mof\u001b[0m \u001b[0mgiven\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1429\u001b[0m   \"\"\"\n\u001b[0;32m-> 1430\u001b[0;31m   return convert_to_tensor_v2(\n\u001b[0m\u001b[1;32m   1431\u001b[0m       value, dtype=dtype, dtype_hint=dtype_hint, name=name)\n\u001b[1;32m   1432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor_v2\u001b[0;34m(value, dtype, dtype_hint, name)\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mconvert_to_tensor_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype_hint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m   \u001b[0;34m\"\"\"Converts the given `value` to a `Tensor`.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m   return convert_to_tensor(\n\u001b[0m\u001b[1;32m   1437\u001b[0m       \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1438\u001b[0m       \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrace_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mtrace_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mconvert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, dtype_hint, ctx, accepted_result_types)\u001b[0m\n\u001b[1;32m   1564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1565\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1566\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1568\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\u001b[0m in \u001b[0;36m_default_conversion_function\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_default_conversion_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mas_ref\u001b[0m  \u001b[0;31m# Unused.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconstant\u001b[0;34m(value, dtype, shape, name)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcalled\u001b[0m \u001b[0mon\u001b[0m \u001b[0ma\u001b[0m \u001b[0msymbolic\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m   \"\"\"\n\u001b[0;32m--> 271\u001b[0;31m   return _constant_impl(value, dtype, shape, name, verify_shape=False,\n\u001b[0m\u001b[1;32m    272\u001b[0m                         allow_broadcast=True)\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_impl\u001b[0;34m(value, dtype, shape, name, verify_shape, allow_broadcast)\u001b[0m\n\u001b[1;32m    281\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tf.constant\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m   \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36m_constant_eager_impl\u001b[0;34m(ctx, value, dtype, shape, verify_shape)\u001b[0m\n\u001b[1;32m    306\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_constant_eager_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m   \u001b[0;34m\"\"\"Creates a constant on the current device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 308\u001b[0;31m   \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvert_to_eager_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    309\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mshape\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\u001b[0m in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    104\u001b[0m       \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_dtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_datatype_enum\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m   \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to convert a NumPy array to a Tensor (Unsupported object type list)."
     ]
    }
   ],
   "source": [
    "# 아래 코드는 그대로 실행하시면 에러가 발생할 것입니다. \n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 위 그림과 같이 4차원의 워드 벡터를 가정합니다. \n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# 숫자로 변환된 텍스트 데이터 [[1, 3, 4, 5], [1, 3, 6, 7], [1, 8, 3, 4, 9]] 에 Embedding 레이어를 적용합니다. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype='object')\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d74ae6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[list([1, 3, 4, 5]) list([1, 3, 6, 7]) list([1, 8, 3, 4, 9])]\n"
     ]
    }
   ],
   "source": [
    "print(raw_inputs) # length: 4, 4, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "78d64e56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 3 4 5 0]\n",
      " [1 3 6 7 0]\n",
      " [1 8 3 4 9]]\n"
     ]
    }
   ],
   "source": [
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "print(raw_inputs) # create \"0\" padding at the end to make them equi-length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ec8a0dee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[-0.02247753  0.02127875  0.04058546  0.01767078]\n",
      "  [-0.00153024  0.03695111  0.03123213 -0.02562163]\n",
      "  [ 0.02828202  0.00110153  0.02493053  0.03329681]\n",
      "  [ 0.03079047  0.01825881  0.04195601 -0.04380346]\n",
      "  [-0.03247847  0.02174127  0.00753707 -0.02673991]]\n",
      "\n",
      " [[-0.02247753  0.02127875  0.04058546  0.01767078]\n",
      "  [-0.00153024  0.03695111  0.03123213 -0.02562163]\n",
      "  [-0.03487188  0.04815641 -0.01143758 -0.03077465]\n",
      "  [ 0.03587227  0.03003094  0.04750068 -0.00115372]\n",
      "  [-0.03247847  0.02174127  0.00753707 -0.02673991]]\n",
      "\n",
      " [[-0.02247753  0.02127875  0.04058546  0.01767078]\n",
      "  [ 0.03366173  0.02932907  0.01736001 -0.01074252]\n",
      "  [-0.00153024  0.03695111  0.03123213 -0.02562163]\n",
      "  [ 0.02828202  0.00110153  0.02493053  0.03329681]\n",
      "  [ 0.0284627   0.00061191 -0.0452726  -0.02873931]]], shape=(3, 5, 4), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(word_to_index)  # 위 예시에서 딕셔너리에 포함된 단어 개수는 10\n",
    "word_vector_dim = 4    # 그림과 같이 4차원의 워드 벡터를 가정합니다.\n",
    "\n",
    "embedding = tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=word_vector_dim, mask_zero=True)\n",
    "\n",
    "# tf.keras.preprocessing.sequence.pad_sequences를 통해 word vector를 모두 일정 길이로 맞춰주어야 \n",
    "# embedding 레이어의 input이 될 수 있음에 주의해 주세요. \n",
    "raw_inputs = np.array(get_encoded_sentences(sentences, word_to_index), dtype=object)\n",
    "raw_inputs = tf.keras.preprocessing.sequence.pad_sequences(raw_inputs,\n",
    "                                                       value=word_to_index['<PAD>'],\n",
    "                                                       padding='post',\n",
    "                                                       maxlen=5)\n",
    "output = embedding(raw_inputs)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497ea71c",
   "metadata": {},
   "source": [
    "- shape (3, 5, 4) \n",
    "    - Data N: 3 \n",
    "    - Each embedding length : 5\n",
    "    - Word vector dimension: 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efa75b8",
   "metadata": {},
   "source": [
    "# 7-6: `RNN`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38cc730d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 8)                 416       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 72        \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4  # 단어 하나를 표현하는 임베딩 벡터의 차원수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(8))   # 가장 널리 쓰이는 RNN인 LSTM 레이어를 사용하였습니다. 이때 LSTM state 벡터의 차원수는 8로 하였습니다. (변경 가능)\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3087a0f6",
   "metadata": {},
   "source": [
    "# 7-7: 꼭 RNN 이어야할까? \n",
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6d834e05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, None, 16)          464       \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, None, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, None, 16)          1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,457\n",
      "Trainable params: 2,457\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "511552bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, None, 4)           40        \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 4)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 40        \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 89\n",
      "Trainable params: 89\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10  # 어휘 사전의 크기입니다(10개의 단어)\n",
    "word_vector_dim = 4   # 단어 하나를 표현하는 임베딩 벡터의 차원 수입니다. \n",
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D()) # What is Global Max Pooling Layer doing here?\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab33de0",
   "metadata": {},
   "source": [
    "> 이 외에도 1-D CNN과 RNN 레이어를 섞어 쓴다거나, FFN(FeedForward Network) 레이어만으로 구성하거나, 혹은 최근 각광받고 있는 Transformer 레이어를 쓰는 등 매우 다양한 시도를 해볼 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1c9ee99",
   "metadata": {},
   "source": [
    "## 7-8: IMDB 데이터셋 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7af7222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "훈련 샘플 개수: 25000, 테스트 개수: 25000\n"
     ]
    }
   ],
   "source": [
    "imdb = tf.keras.datasets.imdb\n",
    "\n",
    "# IMDb 데이터셋 다운로드 \n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=10000)\n",
    "print(f\"훈련 샘플 개수: {len(x_train)}, 테스트 개수: {len(x_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b6b461b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "라벨:  1\n",
      "1번째 리뷰 문장 길이:  218\n",
      "2번째 리뷰 문장 길이:  189\n"
     ]
    }
   ],
   "source": [
    "print(x_train[0])  # 1번째 리뷰데이터\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨\n",
    "print('1번째 리뷰 문장 길이: ', len(x_train[0]))\n",
    "print('2번째 리뷰 문장 길이: ', len(x_train[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "411212c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "word_to_index = imdb.get_word_index()\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "print(index_to_word[1])     # 'the' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 1 이 출력됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fc85d9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "as you with out themselves powerful lets loves their becomes reaching had journalist of lot from anyone to have after out atmosphere never more room and it so heart shows to years of every never going and help moments or of every chest visual movie except her was several of enough more with is now current film as you of mine potentially unfortunately of you than him that with out themselves her get for was camp of you movie sometimes movie that with scary but and to story wonderful that in seeing in character to of 70s musicians with heart had shadows they of here that with her serious to have does when from why what have critics they is you that isn't one will very to as itself with other and in of seen over landed for anyone of and br show's to whether from than out themselves history he name half some br of and odd was two most of mean for 1 any an boat she he should is thought frog but of script you not while history he heart to real at barrel but when from one bit then have two of script their with her nobody most that with wasn't to with armed acting watch an for with heartfelt film want an\n"
     ]
    }
   ],
   "source": [
    "# 보정 전 x_train[0] 데이터\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3bf4044a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BOS>\n",
      "4\n",
      "the\n",
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n"
     ]
    }
   ],
   "source": [
    "#실제 인코딩 인덱스는 제공된 word_to_index에서 index 기준으로 3씩 뒤로 밀려 있습니다.  \n",
    "word_to_index = {k:(v+3) for k,v in word_to_index.items()}\n",
    "\n",
    "# 처음 몇 개 인덱스는 사전에 정의되어 있습니다.\n",
    "word_to_index[\"<PAD>\"] = 0\n",
    "word_to_index[\"<BOS>\"] = 1\n",
    "word_to_index[\"<UNK>\"] = 2  # unknown\n",
    "word_to_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "index_to_word = {index:word for word, index in word_to_index.items()}\n",
    "\n",
    "print(index_to_word[1])     # '<BOS>' 가 출력됩니다. \n",
    "print(word_to_index['the'])  # 4 이 출력됩니다. \n",
    "print(index_to_word[4])     # 'the' 가 출력됩니다.\n",
    "\n",
    "# 보정 후 x_train[0] 데이터\n",
    "print(get_decoded_sentence(x_train[0], index_to_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3652111f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "라벨:  1\n"
     ]
    }
   ],
   "source": [
    "print(get_decoded_sentence(x_train[0], index_to_word))\n",
    "print('라벨: ', y_train[0])  # 1번째 리뷰데이터의 라벨"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4da3f762",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장길이 평균 :  234.75892\n",
      "문장길이 최대 :  2494\n",
      "문장길이 표준편차 :  172.91149458735703\n",
      "pad_sequences maxlen :  580\n",
      "전체 문장의 0.94536%가 maxlen 설정값 이내에 포함됩니다. \n"
     ]
    }
   ],
   "source": [
    "total_data_text = list(x_train) + list(x_test)\n",
    "# 텍스트데이터 문장길이의 리스트를 생성한 후\n",
    "num_tokens = [len(tokens) for tokens in total_data_text]\n",
    "num_tokens = np.array(num_tokens)\n",
    "# 문장길이의 평균값, 최대값, 표준편차를 계산해 본다. \n",
    "print('문장길이 평균 : ', np.mean(num_tokens))\n",
    "print('문장길이 최대 : ', np.max(num_tokens))\n",
    "print('문장길이 표준편차 : ', np.std(num_tokens))\n",
    "\n",
    "# 예를들어, 최대 길이를 (평균 + 2*표준편차)로 한다면,  \n",
    "max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n",
    "maxlen = int(max_tokens)\n",
    "print('pad_sequences maxlen : ', maxlen)\n",
    "print(f'전체 문장의 {np.sum(num_tokens < max_tokens) / len(num_tokens)}%가 maxlen 설정값 이내에 포함됩니다. ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0436e7e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 580)\n"
     ]
    }
   ],
   "source": [
    "x_train = tf.keras.preprocessing.sequence.pad_sequences(x_train,\n",
    "                                                        value=word_to_index[\"<PAD>\"],\n",
    "                                                        padding='post', # 혹은 'pre'\n",
    "                                                        maxlen=maxlen)\n",
    "\n",
    "x_test = tf.keras.preprocessing.sequence.pad_sequences(x_test,\n",
    "                                                       value=word_to_index[\"<PAD>\"],\n",
    "                                                       padding='post', # 혹은 'pre'\n",
    "                                                       maxlen=maxlen)\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57b080c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, None, 16)          160000    \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 160,145\n",
      "Trainable params: 160,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 16  # 워드 벡터의 차원 수 (변경 가능한 하이퍼파라미터)\n",
    "\n",
    "# model 설계 - 딥러닝 모델 코드를 직접 작성해 주세요.\n",
    "model = tf.keras.Sequential()\n",
    "# [[YOUR CODE]]\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D()) # What is Global Max Pooling Layer doing here?\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))  # 최종 출력은 긍정/부정을 나타내는 1dim 입니다.\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95e6d49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 580)\n",
      "(15000,)\n"
     ]
    }
   ],
   "source": [
    "# validation set 10000건 분리\n",
    "x_val = x_train[:10000]   \n",
    "y_val = y_train[:10000]\n",
    "\n",
    "# validation set을 제외한 나머지 15000건\n",
    "partial_x_train = x_train[10000:]  \n",
    "partial_y_train = y_train[10000:]\n",
    "\n",
    "print(partial_x_train.shape)\n",
    "print(partial_y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a5cf4366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 14s 14ms/step - loss: 0.6909 - accuracy: 0.5053 - val_loss: 0.6872 - val_accuracy: 0.5297\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 0s 9ms/step - loss: 0.6801 - accuracy: 0.6311 - val_loss: 0.6731 - val_accuracy: 0.6640\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 0.6581 - accuracy: 0.7195 - val_loss: 0.6455 - val_accuracy: 0.7595\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.6188 - accuracy: 0.8024 - val_loss: 0.6014 - val_accuracy: 0.7868\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.5614 - accuracy: 0.8298 - val_loss: 0.5445 - val_accuracy: 0.8176\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4952 - accuracy: 0.8531 - val_loss: 0.4879 - val_accuracy: 0.8302\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.4333 - accuracy: 0.8673 - val_loss: 0.4425 - val_accuracy: 0.8368\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3813 - accuracy: 0.8780 - val_loss: 0.4085 - val_accuracy: 0.8415\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3390 - accuracy: 0.8885 - val_loss: 0.3847 - val_accuracy: 0.8464\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.3048 - accuracy: 0.8981 - val_loss: 0.3690 - val_accuracy: 0.8480\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2762 - accuracy: 0.9077 - val_loss: 0.3579 - val_accuracy: 0.8496\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2516 - accuracy: 0.9159 - val_loss: 0.3510 - val_accuracy: 0.8513\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2300 - accuracy: 0.9239 - val_loss: 0.3465 - val_accuracy: 0.8516\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.2109 - accuracy: 0.9317 - val_loss: 0.3436 - val_accuracy: 0.8534\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1940 - accuracy: 0.9383 - val_loss: 0.3438 - val_accuracy: 0.8505\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1782 - accuracy: 0.9450 - val_loss: 0.3431 - val_accuracy: 0.8516\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1643 - accuracy: 0.9503 - val_loss: 0.3457 - val_accuracy: 0.8496\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1511 - accuracy: 0.9549 - val_loss: 0.3472 - val_accuracy: 0.8507\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1391 - accuracy: 0.9598 - val_loss: 0.3504 - val_accuracy: 0.8482\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 0.1281 - accuracy: 0.9637 - val_loss: 0.3540 - val_accuracy: 0.8477\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "79c89807",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 1s - loss: 0.3729 - accuracy: 0.8398\n",
      "[0.3728626072406769, 0.8398399949073792]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b239eba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
     ]
    }
   ],
   "source": [
    "history_dict = history.history\n",
    "print(history_dict.keys()) # epoch에 따른 그래프를 그려볼 수 있는 항목들"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1e4bf2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history_dict['accuracy']\n",
    "val_acc = history_dict['val_accuracy']\n",
    "loss = history_dict['loss']\n",
    "val_loss = history_dict['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "# \"bo\"는 \"파란색 점\"입니다\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "# b는 \"파란 실선\"입니다\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ba2ec23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.clf()   # 그림을 초기화합니다\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ade99f",
   "metadata": {},
   "source": [
    "## 7-10: Word2vec 의 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c5daf62",
   "metadata": {},
   "source": [
    "```bash\n",
    "mkdir -p ~/aiffel/sentiment_classification/data\n",
    "pip list | grep gensim\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d1eafaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16)\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = model.layers[0]\n",
    "weights = embedding_layer.get_weights()[0]\n",
    "print(weights.shape)    # shape: (vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "04ea887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습한 Embedding 파라미터를 파일에 써서 저장합니다. \n",
    "word2vec_file_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/word2vec.txt'\n",
    "f = open(word2vec_file_path, 'w')\n",
    "f.write('{} {}\\n'.format(vocab_size-4, word_vector_dim))  # 몇개의 벡터를 얼마 사이즈로 기재할지 타이틀을 씁니다.\n",
    "\n",
    "# 단어 개수(에서 특수문자 4개는 제외하고)만큼의 워드 벡터를 파일에 기록합니다. \n",
    "vectors = model.get_weights()[0]\n",
    "for i in range(4,vocab_size):\n",
    "    f.write('{} {}\\n'.format(index_to_word[i], ' '.join(map(str, list(vectors[i, :])))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "210b6b39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02374794, -0.02333069, -0.03500508, -0.03670327, -0.03027066,\n",
       "       -0.03006826, -0.03635363, -0.02470513, -0.02101255, -0.0216406 ,\n",
       "       -0.01982781, -0.01483747, -0.03293678, -0.02517447, -0.01236309,\n",
       "       -0.02748808], dtype=float32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import Word2VecKeyedVectors\n",
    "\n",
    "word_vectors = Word2VecKeyedVectors.load_word2vec_format(word2vec_file_path, binary=False)\n",
    "vector = word_vectors['computer']\n",
    "vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "e7f6e218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('charming', 0.983350396156311),\n",
       " ('humour', 0.9821362495422363),\n",
       " ('judd', 0.9817014932632446),\n",
       " ('ebert', 0.9791812896728516),\n",
       " ('closer', 0.9786556363105774),\n",
       " ('modern', 0.9782817363739014),\n",
       " ('slips', 0.9776288866996765),\n",
       " ('breathtaking', 0.9772447347640991),\n",
       " ('travel', 0.9761965274810791),\n",
       " ('rabbit', 0.9752947688102722)]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_vectors.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9624c548",
   "metadata": {},
   "source": [
    "```bash\n",
    "ln -s ~/data/GoogleNews-vectors-negative300.bin.gz ~/aiffel/sentiment_classification/data\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8fe13e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.07421875e-01, -2.01171875e-01,  1.23046875e-01,  2.11914062e-01,\n",
       "       -9.13085938e-02,  2.16796875e-01, -1.31835938e-01,  8.30078125e-02,\n",
       "        2.02148438e-01,  4.78515625e-02,  3.66210938e-02, -2.45361328e-02,\n",
       "        2.39257812e-02, -1.60156250e-01, -2.61230469e-02,  9.71679688e-02,\n",
       "       -6.34765625e-02,  1.84570312e-01,  1.70898438e-01, -1.63085938e-01,\n",
       "       -1.09375000e-01,  1.49414062e-01, -4.65393066e-04,  9.61914062e-02,\n",
       "        1.68945312e-01,  2.60925293e-03,  8.93554688e-02,  6.49414062e-02,\n",
       "        3.56445312e-02, -6.93359375e-02, -1.46484375e-01, -1.21093750e-01,\n",
       "       -2.27539062e-01,  2.45361328e-02, -1.24511719e-01, -3.18359375e-01,\n",
       "       -2.20703125e-01,  1.30859375e-01,  3.66210938e-02, -3.63769531e-02,\n",
       "       -1.13281250e-01,  1.95312500e-01,  9.76562500e-02,  1.26953125e-01,\n",
       "        6.59179688e-02,  6.93359375e-02,  1.02539062e-02,  1.75781250e-01,\n",
       "       -1.68945312e-01,  1.21307373e-03, -2.98828125e-01, -1.15234375e-01,\n",
       "        5.66406250e-02, -1.77734375e-01, -2.08984375e-01,  1.76757812e-01,\n",
       "        2.38037109e-02, -2.57812500e-01, -4.46777344e-02,  1.88476562e-01,\n",
       "        5.51757812e-02,  5.02929688e-02, -1.06933594e-01,  1.89453125e-01,\n",
       "       -1.16210938e-01,  8.49609375e-02, -1.71875000e-01,  2.45117188e-01,\n",
       "       -1.73828125e-01, -8.30078125e-03,  4.56542969e-02, -1.61132812e-02,\n",
       "        1.86523438e-01, -6.05468750e-02, -4.17480469e-02,  1.82617188e-01,\n",
       "        2.20703125e-01, -1.22558594e-01, -2.55126953e-02, -3.08593750e-01,\n",
       "        9.13085938e-02,  1.60156250e-01,  1.70898438e-01,  1.19628906e-01,\n",
       "        7.08007812e-02, -2.64892578e-02, -3.08837891e-02,  4.06250000e-01,\n",
       "       -1.01562500e-01,  5.71289062e-02, -7.26318359e-03, -9.17968750e-02,\n",
       "       -1.50390625e-01, -2.55859375e-01,  2.16796875e-01, -3.63769531e-02,\n",
       "        2.24609375e-01,  8.00781250e-02,  1.56250000e-01,  5.27343750e-02,\n",
       "        1.50390625e-01, -1.14746094e-01, -8.64257812e-02,  1.19140625e-01,\n",
       "       -7.17773438e-02,  2.73437500e-01, -1.64062500e-01,  7.29370117e-03,\n",
       "        4.21875000e-01, -1.12792969e-01, -1.35742188e-01, -1.31835938e-01,\n",
       "       -1.37695312e-01, -7.66601562e-02,  6.25000000e-02,  4.98046875e-02,\n",
       "       -1.91406250e-01, -6.03027344e-02,  2.27539062e-01,  5.88378906e-02,\n",
       "       -3.24218750e-01,  5.41992188e-02, -1.35742188e-01,  8.17871094e-03,\n",
       "       -5.24902344e-02, -1.74713135e-03, -9.81445312e-02, -2.86865234e-02,\n",
       "        3.61328125e-02,  2.15820312e-01,  5.98144531e-02, -3.08593750e-01,\n",
       "       -2.27539062e-01,  2.61718750e-01,  9.86328125e-02, -5.07812500e-02,\n",
       "        1.78222656e-02,  1.31835938e-01, -5.35156250e-01, -1.81640625e-01,\n",
       "        1.38671875e-01, -3.10546875e-01, -9.71679688e-02,  1.31835938e-01,\n",
       "       -1.16210938e-01,  7.03125000e-02,  2.85156250e-01,  3.51562500e-02,\n",
       "       -1.01562500e-01, -3.75976562e-02,  1.41601562e-01,  1.42578125e-01,\n",
       "       -5.68847656e-02,  2.65625000e-01, -2.09960938e-01,  9.64355469e-03,\n",
       "       -6.68945312e-02, -4.83398438e-02, -6.10351562e-02,  2.45117188e-01,\n",
       "       -9.66796875e-02,  1.78222656e-02, -1.27929688e-01, -4.78515625e-02,\n",
       "       -7.26318359e-03,  1.79687500e-01,  2.78320312e-02, -2.10937500e-01,\n",
       "       -1.43554688e-01, -1.27929688e-01,  1.73339844e-02, -3.60107422e-03,\n",
       "       -2.04101562e-01,  3.63159180e-03, -1.19628906e-01, -6.15234375e-02,\n",
       "        5.93261719e-02, -3.23486328e-03, -1.70898438e-01, -3.14941406e-02,\n",
       "       -8.88671875e-02, -2.89062500e-01,  3.44238281e-02, -1.87500000e-01,\n",
       "        2.94921875e-01,  1.58203125e-01, -1.19628906e-01,  7.61718750e-02,\n",
       "        6.39648438e-02, -4.68750000e-02, -6.83593750e-02,  1.21459961e-02,\n",
       "       -1.44531250e-01,  4.54101562e-02,  3.68652344e-02,  3.88671875e-01,\n",
       "        1.45507812e-01, -2.55859375e-01, -4.46777344e-02, -1.33789062e-01,\n",
       "       -1.38671875e-01,  6.59179688e-02,  1.37695312e-01,  1.14746094e-01,\n",
       "        2.03125000e-01, -4.78515625e-02,  1.80664062e-02, -8.54492188e-02,\n",
       "       -2.48046875e-01, -3.39843750e-01, -2.83203125e-02,  1.05468750e-01,\n",
       "       -2.14843750e-01, -8.74023438e-02,  7.12890625e-02,  1.87500000e-01,\n",
       "       -1.12304688e-01,  2.73437500e-01, -3.26171875e-01, -1.77734375e-01,\n",
       "       -4.24804688e-02, -2.69531250e-01,  6.64062500e-02, -6.88476562e-02,\n",
       "       -1.99218750e-01, -7.03125000e-02, -2.43164062e-01, -3.66210938e-02,\n",
       "       -7.37304688e-02, -1.77734375e-01,  9.17968750e-02, -1.25000000e-01,\n",
       "       -1.65039062e-01, -3.57421875e-01, -2.85156250e-01, -1.66992188e-01,\n",
       "        1.97265625e-01, -1.53320312e-01,  2.31933594e-02,  2.06054688e-01,\n",
       "        1.80664062e-01, -2.74658203e-02, -1.92382812e-01, -9.61914062e-02,\n",
       "       -1.06811523e-02, -4.73632812e-02,  6.54296875e-02, -1.25732422e-02,\n",
       "        1.78222656e-02, -8.00781250e-02, -2.59765625e-01,  9.37500000e-02,\n",
       "       -7.81250000e-02,  4.68750000e-02, -2.22167969e-02,  1.86767578e-02,\n",
       "        3.11279297e-02,  1.04980469e-02, -1.69921875e-01,  2.58789062e-02,\n",
       "       -3.41796875e-02, -1.44042969e-02, -5.46875000e-02, -8.78906250e-02,\n",
       "        1.96838379e-03,  2.23632812e-01, -1.36718750e-01,  1.75781250e-01,\n",
       "       -1.63085938e-01,  1.87500000e-01,  3.44238281e-02, -5.63964844e-02,\n",
       "       -2.27689743e-05,  4.27246094e-02,  5.81054688e-02, -1.07910156e-01,\n",
       "       -3.88183594e-02, -2.69531250e-01,  3.34472656e-02,  9.81445312e-02,\n",
       "        5.63964844e-02,  2.23632812e-01, -5.49316406e-02,  1.46484375e-01,\n",
       "        5.93261719e-02, -2.19726562e-01,  6.39648438e-02,  1.66015625e-02,\n",
       "        4.56542969e-02,  3.26171875e-01, -3.80859375e-01,  1.70898438e-01,\n",
       "        5.66406250e-02, -1.04492188e-01,  1.38671875e-01, -1.57226562e-01,\n",
       "        3.23486328e-03, -4.80957031e-02, -2.48046875e-01, -6.20117188e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "\n",
    "word2vec_path = os.getenv('HOME')+'/aiffel/sentiment_classification/data/GoogleNews-vectors-negative300.bin.gz'\n",
    "word2vec = KeyedVectors.load_word2vec_format(word2vec_path, binary=True, limit=1000000)\n",
    "vector = word2vec['computer']\n",
    "vector     # 무려 300dim의 워드 벡터입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a7a942a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모리를 다소 많이 소비하는 작업이니 유의해 주세요.\n",
    "# word2vec.similar_by_word(\"love\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a54251b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원수\n",
    "embedding_matrix = np.random.rand(vocab_size, word_vector_dim)\n",
    "\n",
    "# embedding_matrix에 Word2Vec 워드 벡터를 단어 하나씩마다 차례차례 카피한다.\n",
    "for i in range(4,vocab_size):\n",
    "    if index_to_word[i] in word2vec:\n",
    "        embedding_matrix[i] = word2vec[index_to_word[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "ea3d47ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 580, 300)          3000000   \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 574, 16)           33616     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 114, 16)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 108, 16)           1808      \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_3 (Glob (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 136       \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 3,035,569\n",
      "Trainable params: 3,035,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.initializers import Constant\n",
    "\n",
    "vocab_size = 10000    # 어휘 사전의 크기입니다(10,000개의 단어)\n",
    "word_vector_dim = 300  # 워드 벡터의 차원 수 \n",
    "\n",
    "# 모델 구성\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, \n",
    "                                 word_vector_dim, \n",
    "                                 embeddings_initializer=Constant(embedding_matrix),  # 카피한 임베딩을 여기서 활용\n",
    "                                 input_length=maxlen, \n",
    "                                 trainable=True))   # trainable을 True로 주면 Fine-tuning\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.MaxPooling1D(5))\n",
    "model.add(tf.keras.layers.Conv1D(16, 7, activation='relu'))\n",
    "model.add(tf.keras.layers.GlobalMaxPooling1D())\n",
    "model.add(tf.keras.layers.Dense(8, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ecdc4ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "30/30 [==============================] - 6s 97ms/step - loss: 0.7042 - accuracy: 0.5145 - val_loss: 0.6870 - val_accuracy: 0.5408\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.6675 - accuracy: 0.6107 - val_loss: 0.6637 - val_accuracy: 0.6135\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.6091 - accuracy: 0.7097 - val_loss: 0.5705 - val_accuracy: 0.7442\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.4356 - accuracy: 0.8322 - val_loss: 0.3915 - val_accuracy: 0.8259\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 2s 71ms/step - loss: 0.2853 - accuracy: 0.8868 - val_loss: 0.3217 - val_accuracy: 0.8611\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.2035 - accuracy: 0.9252 - val_loss: 0.3022 - val_accuracy: 0.8721\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.1474 - accuracy: 0.9545 - val_loss: 0.3476 - val_accuracy: 0.8602\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.1158 - accuracy: 0.9657 - val_loss: 0.3275 - val_accuracy: 0.8696\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0745 - accuracy: 0.9833 - val_loss: 0.3428 - val_accuracy: 0.8689\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0536 - accuracy: 0.9906 - val_loss: 0.3565 - val_accuracy: 0.8694\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0352 - accuracy: 0.9963 - val_loss: 0.3699 - val_accuracy: 0.8679\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0232 - accuracy: 0.9987 - val_loss: 0.3891 - val_accuracy: 0.8682\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0167 - accuracy: 0.9993 - val_loss: 0.4182 - val_accuracy: 0.8675\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0121 - accuracy: 0.9995 - val_loss: 0.4245 - val_accuracy: 0.8697\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 2s 73ms/step - loss: 0.0084 - accuracy: 0.9998 - val_loss: 0.4408 - val_accuracy: 0.8692\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0063 - accuracy: 0.9999 - val_loss: 0.4560 - val_accuracy: 0.8691\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0050 - accuracy: 0.9999 - val_loss: 0.4696 - val_accuracy: 0.8690\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0041 - accuracy: 0.9999 - val_loss: 0.4821 - val_accuracy: 0.8694\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0034 - accuracy: 0.9999 - val_loss: 0.4941 - val_accuracy: 0.8687\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 2s 72ms/step - loss: 0.0028 - accuracy: 0.9999 - val_loss: 0.5054 - val_accuracy: 0.8687\n"
     ]
    }
   ],
   "source": [
    "# 학습의 진행\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "              \n",
    "epochs=20  # 몇 epoch를 훈련하면 좋을지 결과를 보면서 바꾸어 봅시다. \n",
    "\n",
    "history = model.fit(partial_x_train,\n",
    "                    partial_y_train,\n",
    "                    epochs=epochs,\n",
    "                    batch_size=512,\n",
    "                    validation_data=(x_val, y_val),\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b77c5de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 2s - loss: 0.5304 - accuracy: 0.8639\n",
      "[0.5303584337234497, 0.8638799786567688]\n"
     ]
    }
   ],
   "source": [
    "# 테스트셋을 통한 모델 평가\n",
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7a092a",
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
